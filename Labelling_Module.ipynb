{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seilsepour/SSTSA/blob/main/Labelling_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmUJ9X9WFB52"
      },
      "source": [
        "https://colab.research.google.com/drive/1tUr5t0ZJ-I4Ni40dkbjku92HAU5SyR_2?usp=sharing#scrollTo=wK7GAJI79bAZ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QydnMUEHvHtj"
      },
      "outputs": [],
      "source": [
        "!pip install sentistrength"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycm"
      ],
      "metadata": {
        "id": "uu7W5GkU0AT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7h-xrbKefas"
      },
      "outputs": [],
      "source": [
        "!pip install afinn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjWrf2vnyNND"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade gensim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2WxORdcmhiE"
      },
      "outputs": [],
      "source": [
        "!pip install -q vaderSentiment\n",
        "!pip install -q textblob\n",
        "!pip install -q flair"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LaohjdE5tkF"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUjAhJvO2bKZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import string\n",
        "from __future__ import print_function\n",
        "\n",
        "import gensim\n",
        "from scipy import spatial\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y65_m7Ar296U"
      },
      "outputs": [],
      "source": [
        "d2vModelModel = '/MYDRIVE/My Drive/Colab Notebooks/SSTSA/data/d2vModelPangLee-00-11-04.model'\n",
        "d2vModelTxt = '/MYDRIVE/My Drive/Colab Notebooks/SSTSA/data/d2vModelPangLee-00-11-04.txt'\n",
        "\n",
        "w2vMovieTxt = '/MYDRIVE/My Drive/Colab Notebooks/SSTSA/data/w2vBook-01-02-17.txt'\n",
        "w2vMovieM = '/MYDRIVE/My Drive/Colab Notebooks/SSTSA/data/w2vBook-01-02-17.h5'\n",
        "#pangLeeDataset = '/MYDRIVE/My Drive/Colab Notebooks/SecondPaper/data/Preprocessed-Opinion-Words.csv'\n",
        "#running again to compute just some columns\n",
        "pangLeeDataset = '/MYDRIVE/My Drive/Colab Notebooks/SSTSA/data/MR02-Opinion-Words-ALL.xlsx'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Om5Ohm3356w"
      },
      "outputs": [],
      "source": [
        "#Making Word2vec\n",
        "embeddingDim = 300\n",
        "maxLen = embeddingDim\n",
        "testSize=0.2\n",
        "windowSize=5\n",
        "minCount=1\n",
        "iterCount=10\n",
        "sG = 0 #skip gram wil be used\n",
        "\n",
        "\n",
        "#Making Model\n",
        "validationSplit = 0.2\n",
        "#maxFeatures = numWords\n",
        "maxLen = 500\n",
        "isTrainable = False\n",
        "batchSize = 1000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFhVGwHf3920"
      },
      "source": [
        "# Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QO-IjgPj4Aft"
      },
      "outputs": [],
      "source": [
        "#No need in local\n",
        "from google.colab import drive\n",
        "drive.mount('/MYDRIVE', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99xDGAmzpOT1"
      },
      "source": [
        "# Common"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SVkUTRotVh1"
      },
      "source": [
        "https://radimrehurek.com/gensim/auto_examples/tutorials/run_wmd.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzU_EkgMtQYk"
      },
      "outputs": [],
      "source": [
        "#especially for word mover\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import download\n",
        "download('stopwords')  # Download stopwords list.\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def remove_pronoun(tokens):\n",
        "        pronouns = ['i', 'you', 'he', 'she', 'it', 'we', 'they', 'what', 'who','me', 'him', 'her', 'it', 'us', 'you', 'them', 'whom','mine', 'yours', 'his', 'hers', 'ours', 'theirs','this', 'that', 'these', 'those']\n",
        "\n",
        "        for token in tokens:\n",
        "            for pronoun in pronouns:\n",
        "                if token == pronoun:\n",
        "                    #print(\"^^^^^^^^\\:   \", token, pronoun)\n",
        "                    tokens.remove(token)\n",
        "                    break\n",
        "\n",
        "\n",
        "        return tokens\n",
        "\n",
        "def preprocess(sentence):\n",
        "            user_review = sentence\n",
        "            #user_review = self.split_review_text(user_review)\n",
        "            user_review = user_review.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
        "            user_review = user_review.strip().replace(\".\", \".\").replace(\".\", \".\")\n",
        "            user_review = user_review.lower()\n",
        "            user_review =  user_review.replace(\",\", \" \")\n",
        "            user_review =  user_review.replace(\"'\", \" \")\n",
        "            user_review =  user_review.replace(\".\", \" \")\n",
        "            user_review =  user_review.replace(\"-\", \" \")\n",
        "            user_review =  user_review.replace(\"(\", \" \")\n",
        "            user_review =  user_review.replace(\")\", \" \")\n",
        "            user_review =  user_review.replace(\"<\", \" \")\n",
        "            user_review =  user_review.replace(\">\", \" \")\n",
        "            user_review = ''.join([i for i in user_review if not i.isdigit()])\n",
        "            user_review = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',user_review)\n",
        "            user_review = re.sub(r'#([^\\s]+)', r'\\1', user_review)\n",
        "            \"\"\" Removes unicode strings like \"\\u002c\" and \"x96\" \"\"\"\n",
        "            user_review = re.sub(r'(\\\\u[0-9A-Fa-f]+)',r'', user_review)\n",
        "            user_review = re.sub(r'[^\\x00-\\x7f]',r'',user_review)\n",
        "            user_review = re.sub(r\"(\\?)\\1+\", '', user_review)\n",
        "            user_review = re.sub(r\"(\\.)\\1+\", '', user_review)\n",
        "            user_review = re.sub(r\"(\\!)\\1+\", '', user_review)\n",
        "            return [w for w in user_review.lower().split() if w not in stop_words]\n",
        "\n",
        "\n",
        "def preprocess2(row):\n",
        "            user_review = row[1]\n",
        "            #user_review = self.split_review_text(user_review)\n",
        "            user_review = user_review.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
        "            user_review = user_review.strip().replace(\".\", \".\").replace(\".\", \".\")\n",
        "            user_review = user_review.lower()\n",
        "            user_review =  user_review.replace(\",\", \" \")\n",
        "            user_review =  user_review.replace(\"'\", \" \")\n",
        "            user_review =  user_review.replace(\".\", \" \")\n",
        "            user_review =  user_review.replace(\"-\", \" \")\n",
        "            user_review =  user_review.replace(\"(\", \" \")\n",
        "            user_review =  user_review.replace(\")\", \" \")\n",
        "            user_review =  user_review.replace(\"<\", \" \")\n",
        "            user_review =  user_review.replace(\">\", \" \")\n",
        "            user_review = ''.join([i for i in user_review if not i.isdigit()])\n",
        "            user_review = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',user_review)\n",
        "            user_review = re.sub(r'#([^\\s]+)', r'\\1', user_review)\n",
        "            \"\"\" Removes unicode strings like \"\\u002c\" and \"x96\" \"\"\"\n",
        "            user_review = re.sub(r'(\\\\u[0-9A-Fa-f]+)',r'', user_review)\n",
        "            user_review = re.sub(r'[^\\x00-\\x7f]',r'',user_review)\n",
        "            user_review = re.sub(r\"(\\?)\\1+\", '', user_review)\n",
        "            user_review = re.sub(r\"(\\.)\\1+\", '', user_review)\n",
        "            user_review = re.sub(r\"(\\!)\\1+\", '', user_review)\n",
        "            return [w for w in user_review.lower().split() if w not in stop_words]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpp7lRL3xpQz"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from imblearn.ensemble import BalancedBaggingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from pycm import ConfusionMatrix\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "import gzip\n",
        "import gensim\n",
        "import logging\n",
        "\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus.reader import CategorizedPlaintextCorpusReader\n",
        "from nltk import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.seterr(divide='ignore', invalid='ignore')\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "class TF_IDF(object):\n",
        "    def __init__(self):\n",
        "        print(\"..\")\n",
        "\n",
        "    def get_tf_idf(self, X):\n",
        "        vectorizer = TfidfVectorizer(ngram_range=(1,2), tokenizer=lambda x: x.split())\n",
        "        X = vectorizer.fit_transform(X)\n",
        "        #print(X)\n",
        "        return X\n",
        "\n",
        "\n",
        "class Performance(object):\n",
        "\n",
        "\n",
        "    def get_results(self, labels, predictions):\n",
        "        from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "        conf_matrix = confusion_matrix(labels, predictions)\n",
        "\n",
        "        #print(conf_matrix)\n",
        "\n",
        "        precision = np.diag(conf_matrix) / np.sum(conf_matrix, axis = 0)\n",
        "        recall = np.diag(conf_matrix) / np.sum(conf_matrix, axis = 1)\n",
        "\n",
        "        accuracy =  np.sum(np.diag(conf_matrix) / np.sum(conf_matrix))\n",
        "\n",
        "        #print(\"Total: \" , np.sum(conf_matrix))\n",
        "\n",
        "        #print(\"Correct/Incorrect : \", np.sum(np.diag(conf_matrix) ),  np.sum(conf_matrix) -  np.sum(np.diag(conf_matrix) ))\n",
        "        #print(\"Denominator:\", np.sum(conf_matrix, axis = 0))\n",
        "        #print(np.mean(precision))\n",
        "        #print(np.mean(recall))\n",
        "\n",
        "        precision = np.mean(precision)\n",
        "        recall = np.mean(recall)\n",
        "\n",
        "        #print(\"Precision: \", precision)\n",
        "        #print(\"Recall: \" , recall)\n",
        "\n",
        "\n",
        "        f1_score = (2 * precision * recall) / (precision + recall)\n",
        "        #print(\"F-1 Score:  -----  \", f1_score)\n",
        "        return conf_matrix, precision,  recall, f1_score,  accuracy\n",
        "\n",
        "\n",
        "    def calculateMCC(self, labels, predictions):\n",
        "\n",
        "        cm = ConfusionMatrix(labels, predictions, digit=5)\n",
        "\n",
        "        #print(\"\\n Kappa-AC1: \", cm.Kappa, cm.AC1)\n",
        "        #print(\"\\nMCC:\")\n",
        "        #print(cm.MCC)\n",
        "        return cm.MCC\n",
        "\n",
        "\n",
        "    def calculate_roc_auc_score(self, labels, predictions):\n",
        "        score = roc_auc_score(labels, predictions)\n",
        "        return score\n",
        "        #print(\"ROC:\" , score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7zJiMTbjfE5"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itQNc-b-4vhj"
      },
      "outputs": [],
      "source": [
        "dfPangLee = pd.DataFrame()\n",
        "dfPangLee = pd.read_excel(pangLeeDataset)\n",
        "#dfPangLee = pd.read_csv(pangLeeDataset, encoding = 'utf-8', header = None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfPangLee.columns"
      ],
      "metadata": {
        "id": "0io7RNxU0OIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfPangLee.head(2)"
      ],
      "metadata": {
        "id": "LZv2pm6n0iPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGEbOAlKFyV7"
      },
      "outputs": [],
      "source": [
        "#dfPangLee.columns = ['id','ActualText', 'PreprocessedText' ,'Positives', 'Negatives', 'ActualLabel', 'PredictedLabel', 'ConfidenseScore', 'Type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9MFN68Ywr62"
      },
      "outputs": [],
      "source": [
        "dfPangLee.columns = ['id','ActualText' ,'Positives','Positive_Negations', 'Negatives', 'Negative_Negations', 'ActualLabel', 'Type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTDDBXo_40Sn"
      },
      "outputs": [],
      "source": [
        "dfPangLee2 = dfPangLee\n",
        "print(len(dfPangLee2))\n",
        "\n",
        "print(dfPangLee2.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub3cZGXGzI-0"
      },
      "outputs": [],
      "source": [
        "targets = dfPangLee2['ActualLabel']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHC_zDxl9xvw"
      },
      "source": [
        "# Labeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IgRcMDOXg3S"
      },
      "outputs": [],
      "source": [
        "dfPangLee2.insert(8, \"PreProcessed\",\" \")\n",
        "dfPangLee2.insert(9, \"score_c\",0.0)\n",
        "dfPangLee2.insert(10, \"cos_p\",0.0)\n",
        "dfPangLee2.insert(11, \"cos_n\",0.0)\n",
        "dfPangLee2.insert(12, \"comp_c\",0.0)\n",
        "\n",
        "dfPangLee2.insert(13, \"score_dist\",0.0) # distance\n",
        "dfPangLee2.insert(14, \"dist_p\",0.0)\n",
        "dfPangLee2.insert(15, \"dist_n\",0.0)\n",
        "dfPangLee2.insert(16, \"comp_dist\",0.0)\n",
        "\n",
        "dfPangLee2.insert(17, \"score_sc\",0.0) #soft cosine\n",
        "dfPangLee2.insert(18, \"softcos_p\",0.0)\n",
        "dfPangLee2.insert(19, \"softcos_n\",0.0)\n",
        "dfPangLee2.insert(20, \"comp_sc\",0.0)\n",
        "\n",
        "dfPangLee2.insert(21, \"score_csc\",0.0) # cosine + soft cosine\n",
        "dfPangLee2.insert(22, \"csc_p\",0.0)\n",
        "dfPangLee2.insert(23, \"csc_n\",0.0)\n",
        "dfPangLee2.insert(24, \"comp_csc\",0.0)\n",
        "\n",
        "\n",
        "dfPangLee2.insert(25, \"VADER\",0.0)\n",
        "dfPangLee2.insert(26, \"comp_VADER\",0.0)\n",
        "\n",
        "dfPangLee2.insert(27, \"BLOB\",0.0)\n",
        "dfPangLee2.insert(28, \"comp_BLOB\",0.0)\n",
        "\n",
        "dfPangLee2.insert(29, \"FLAIR\",0.0)\n",
        "dfPangLee2.insert(30, \"comp_FLAIR\",0.0)\n",
        "\n",
        "dfPangLee2.insert(31, \"result_positive_minus\",0.0)\n",
        "dfPangLee2.insert(32, \"result_negative_minus\",0.0)\n",
        "dfPangLee2.insert(33, \"score_overall_minus\",0.0)\n",
        "dfPangLee2.insert(34, \"evaluation_minus\",0.0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-PKsEQLfhQj"
      },
      "outputs": [],
      "source": [
        "dfPangLee2.insert(35, \"AFINN\",0.0)\n",
        "dfPangLee2.insert(36, \"comp_AFINN\",0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MZfe_VwnWDe"
      },
      "outputs": [],
      "source": [
        "dfPangLee2.insert(37, \"MIX\",0.0)\n",
        "dfPangLee2.insert(38, \"comp_MIX\",0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmkM3a3VotCN"
      },
      "outputs": [],
      "source": [
        "dfPangLee2.insert(39, \"evaluation_MIX\",0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hljzl-QqvRQp"
      },
      "outputs": [],
      "source": [
        "dfPangLee2.insert(40, \"SENTI\",0.0)\n",
        "dfPangLee2.insert(41, \"comp_SENTI\",0.0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfPangLee2['PreProcessed'] = dfPangLee2.apply (lambda row: preprocess2(row), axis=1)"
      ],
      "metadata": {
        "id": "OZLEyKpZjufg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uQIhXXnj2hU"
      },
      "source": [
        "# Make Doc2Vec and SAVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfv00nLsrqm7"
      },
      "outputs": [],
      "source": [
        "def prepare_data(dfTemp, tokens_only=False):\n",
        "    for index, row in dfTemp.iterrows():\n",
        "            #tokens = gensim.utils.simple_preprocess(row[1])\n",
        "            #tokens = preprocess(row['ActualText'])\n",
        "            tokens = row['PreProcessed']\n",
        "            if tokens_only:\n",
        "                yield tokens\n",
        "            else:\n",
        "                # For training data, add tags\n",
        "                yield gensim.models.doc2vec.TaggedDocument(tokens, [row[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKAj67tq6Bbf"
      },
      "outputs": [],
      "source": [
        "dfTrain = dfPangLee2[dfPangLee2['Type'] == 'train']\n",
        "dfTest = dfPangLee2[dfPangLee2['Type'] == 'test']\n",
        "print(len(dfTrain))\n",
        "print(len(dfTest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rXdn-0d7c6Q"
      },
      "outputs": [],
      "source": [
        "train_corpus = list(prepare_data(dfTrain))\n",
        "test_corpus = list(prepare_data(dfTest, tokens_only=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yi1ORqbq7xyJ"
      },
      "outputs": [],
      "source": [
        "len(train_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMMekWr17_M3"
      },
      "outputs": [],
      "source": [
        "len(test_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOKdJ1RZkBjM"
      },
      "outputs": [],
      "source": [
        "print(train_corpus[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2J0SU5b5kCTT"
      },
      "outputs": [],
      "source": [
        "print(test_corpus[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdY7OBJSkKJQ"
      },
      "outputs": [],
      "source": [
        "d2vModel = gensim.models.doc2vec.Doc2Vec(vector_size=300, min_count=2, epochs=40, seed = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDlr9p-FkK-6"
      },
      "outputs": [],
      "source": [
        "d2vModel.build_vocab(train_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0qTJt5jkSRv"
      },
      "outputs": [],
      "source": [
        "#print(f\"Word 'penalty' appeared {d2vModel.wv.get_vecator('penalty', 'count')} times in the training corpus.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Rk2_KdmkU_D"
      },
      "outputs": [],
      "source": [
        "d2vModel.train(train_corpus, total_examples=d2vModel.corpus_count, epochs=d2vModel.epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exmaUN89xvdT"
      },
      "outputs": [],
      "source": [
        "d2vModel.save(d2vModelModel)\n",
        "d2vModel.save(d2vModelTxt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2dU67GHyuyq"
      },
      "source": [
        "# Load D2V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWuEc0wIyyki"
      },
      "outputs": [],
      "source": [
        "from gensim.models.doc2vec import Doc2Vec\n",
        "d2vModel = Doc2Vec.load(d2vModelModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5wrgl-opX2c"
      },
      "source": [
        "# Make Word2Vec and SAVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C50v6tdupbM4"
      },
      "outputs": [],
      "source": [
        "reviewMovieLines = list()\n",
        "for index, row in dfPangLee2.iterrows():\n",
        "  reviewMovieLines.append( row[\"PreProcessed\"] )\n",
        "  #print( row[0].split())\n",
        "  #reviewMovieLines.append( str(row[1]).split() )\n",
        "\n",
        "\n",
        "print(len(reviewMovieLines))\n",
        "\n",
        "\n",
        "\n",
        "w2vMovie = gensim.models.Word2Vec( sentences=reviewMovieLines, vector_size= 200, epochs = 10,   window=windowSize, workers=4,\n",
        "                                  min_count=1,  sg = sG, seed=1 )\n",
        "\n",
        "w2vGensimModel = gensim.models.Word2Vec()\n",
        "#vocab size\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvx1Es0XRnfY"
      },
      "outputs": [],
      "source": [
        "print('Vocabulary size: %d' % len(w2vMovie.wv))\n",
        "\n",
        "\n",
        "w2vMovie.wv.save_word2vec_format( w2vMovieTxt, binary = False)\n",
        "w2vMovie.save(w2vMovieM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itAoBbLkzFnl"
      },
      "source": [
        "# Load W2V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjxbZtxvzE2h"
      },
      "outputs": [],
      "source": [
        "w2vMovie = gensim.models.Word2Vec.load(w2vMovieM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY5fGTSSpFD1"
      },
      "source": [
        "# JS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hb-rX-Hpfnu"
      },
      "source": [
        "https://machinelearningmastery.com/divergence-between-probability-distributions/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzfPan0uI3AG"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import jensenshannon\n",
        "from numpy import asarray\n",
        "#js_pq = jensenshannon(p, q, base=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3crobmFoYo3k"
      },
      "outputs": [],
      "source": [
        "dfPangLee2.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhplSW9WoWqX"
      },
      "source": [
        "# Soft Cosine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_1AlC23olKa"
      },
      "source": [
        "https://radimrehurek.com/gensim//auto_examples/tutorials/run_scm.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ou8dFHlOe2_J"
      },
      "outputs": [],
      "source": [
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import TfidfModel\n",
        "from gensim.similarities import SparseTermSimilarityMatrix, WordEmbeddingSimilarityIndex\n",
        "#from gensim.similarities import WordEmbeddingSimilarityIndex\n",
        "\n",
        "\n",
        "documents = list()\n",
        "for index, row in dfPangLee2.iterrows():\n",
        "  documents.append( row['PreProcessed'] )\n",
        "\n",
        "dictionary = Dictionary(documents)\n",
        "\n",
        "documents2 = list()\n",
        "for document in documents:\n",
        "  documents2.append(dictionary.doc2bow(document))\n",
        "\n",
        "import gensim.downloader as api\n",
        "#model = api.load('word2vec-google-news-300')\n",
        "\n",
        "\n",
        "tfidf = TfidfModel(documents2)\n",
        "termsim_index = WordEmbeddingSimilarityIndex(w2vMovie.wv)\n",
        "#termsim_index = WordEmbeddingSimilarityIndex(model)\n",
        "\n",
        "termsim_matrix = SparseTermSimilarityMatrix(termsim_index, dictionary, tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZGGaClBfAh7"
      },
      "outputs": [],
      "source": [
        "def Calculate_SoftCosine_Similarity(sent1,sent2):\n",
        "  sent1 = preprocess(sent1)\n",
        "  sent2 = preprocess(sent2)\n",
        "  sent1 = dictionary.doc2bow(sent1)\n",
        "  sent2 = dictionary.doc2bow(sent2)\n",
        "  sent1 = tfidf[sent1]\n",
        "  sent2 = tfidf[sent2]\n",
        "  similarity = termsim_matrix.inner_product(sent1, sent2, normalized=(True, True))\n",
        "  return similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPR5u51toadp"
      },
      "outputs": [],
      "source": [
        "#dfPangLee2 = dfPangLee\n",
        "#dfPangLee2 = dfPangLee2[dfPangLee2[\"id\"] < 10 ]\n",
        "for index, row in dfPangLee2.iterrows():\n",
        "    #text = gensim.utils.simple_preprocess(row[1])\n",
        "    text = row[\"PreProcessed\"]\n",
        "\n",
        "    positives = row[\"Positives\"].replace('[','').replace(']','').replace(\"'\",'').replace(' ','').split(',')\n",
        "    negatives = row[\"Negatives\"].replace('[','').replace(']','').replace(\"'\",'').replace(' ','').split(',')\n",
        "\n",
        "\n",
        "    positive_negations = row[\"Positive_Negations\"].replace('[','').replace(']','').replace(\"'\",'').replace(' ','').split(',')\n",
        "    negative_negations = row[\"Negative_Negations\"].replace('[','').replace(']','').replace(\"'\",'').replace(' ','').split(',')\n",
        "\n",
        "\n",
        "\n",
        "    sc_p = 0\n",
        "    sc_n = 0\n",
        "    for pos in positives:\n",
        "        sc_p =  sc_p + Calculate_SoftCosine_Similarity(row['ActualText'],pos)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for neg in negatives:\n",
        "        sc_n =  sc_n + Calculate_SoftCosine_Similarity(row['ActualText'],neg)\n",
        "\n",
        "\n",
        "    #Adding negations\n",
        "    for pos in positive_negations:\n",
        "        sc_p =  sc_p - Calculate_SoftCosine_Similarity(row['ActualText'],pos)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for neg in negative_negations:\n",
        "        sc_n =  sc_n - Calculate_SoftCosine_Similarity(row['ActualText'],neg)\n",
        "\n",
        "\n",
        "\n",
        "    positives2 = positives\n",
        "    negatives2 = negatives\n",
        "    positives2 = ' '.join(dict.fromkeys(positives2))\n",
        "    negatives2 = ' '.join(dict.fromkeys(negatives2))\n",
        "\n",
        "    #print(positives2)\n",
        "    #print(negatives2)\n",
        "\n",
        "\n",
        "\n",
        "    sc_p =  sc_p + Calculate_SoftCosine_Similarity(row['ActualText'],positives2)\n",
        "    sc_n =  sc_n + Calculate_SoftCosine_Similarity(row['ActualText'],negatives2)\n",
        "    #print(sc_p)\n",
        "    #print(sc_n)\n",
        "\n",
        "    dfPangLee2.loc[index, 'softcos_p'] = sc_p\n",
        "    dfPangLee2.loc[index, 'softcos_n'] = sc_n\n",
        "\n",
        "    if sc_p > sc_n:\n",
        "         dfPangLee2.loc[index, 'score_sc'] = 1\n",
        "         if row[\"ActualLabel\"] == 1:\n",
        "           dfPangLee2.loc[index, 'comp_sc'] = \"match\"\n",
        "         else:\n",
        "            dfPangLee2.loc[index, 'comp_sc'] = \"not match\"\n",
        "\n",
        "    else:\n",
        "         dfPangLee2.loc[index, 'score_sc'] = 0\n",
        "         if row[\"ActualLabel\"] == 0:\n",
        "           dfPangLee2.loc[index, 'comp_sc'] = \"match\"\n",
        "         else:\n",
        "            dfPangLee2.loc[index, 'comp_sc'] = \"not match\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6Pvl06zfI1M"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"comp_sc\"] == \"not match\" ]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJV0ERuuoOth"
      },
      "source": [
        "# Cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vPwYNB2sS4q"
      },
      "outputs": [],
      "source": [
        "#dfPangLee2 = dfPangLee2[dfPangLee2[\"id\"] < 1 ]\n",
        "for index, row in dfPangLee2.iterrows():\n",
        "    #text = gensim.utils.simple_preprocess(row[1])\n",
        "\n",
        "    #text = preprocess(row['ActualText'])\n",
        "    text = row[\"PreProcessed\"]\n",
        "    #print(text)\n",
        "    vec_p =  np.zeros(300)\n",
        "    vec_n =  np.zeros(300)\n",
        "    vec_main = d2vModel.infer_vector(text)\n",
        "    positives = row['Positives'].replace('[','').replace(']','').replace(\"'\",'').replace(' ','').split(',')\n",
        "    #print(positives)\n",
        "    negatives = row['Negatives'].replace('[','').replace(']','').replace(\"'\",'').replace(' ','').split(',')\n",
        "    #print(negatives)\n",
        "    positive_negations = row['Positive_Negations'].replace('[','').replace(']','').replace(\"'\",'').replace(' ','').split(',')\n",
        "\n",
        "    negative_negations = row['Negative_Negations'].replace('[','').replace(']','').replace(\"'\",'').replace(' ','').split(',')\n",
        "\n",
        "\n",
        "\n",
        "    cos_p = 0\n",
        "    cos_n = 0\n",
        "    for pos in positives:\n",
        "        vec_p =  d2vModel.infer_vector([pos])\n",
        "        #print(vec_p)\n",
        "        cos_p = cos_p + spatial.distance.cosine(vec_main, vec_p)\n",
        "        #print(cos_p)\n",
        "\n",
        "\n",
        "\n",
        "    for neg in negatives:\n",
        "        vec_n =  d2vModel.infer_vector([neg])\n",
        "        #print(vec_n)\n",
        "        cos_n = cos_n + spatial.distance.cosine(vec_main, vec_n)\n",
        "        #print(cos_n)\n",
        "\n",
        "    vec_p =  d2vModel.infer_vector(positives)\n",
        "    vec_n =  d2vModel.infer_vector(negatives)\n",
        "    cos_p = cos_p + spatial.distance.cosine(vec_main, vec_p)\n",
        "    cos_n = cos_n + spatial.distance.cosine(vec_main, vec_n)\n",
        "\n",
        "\n",
        "    #Adding Negations\n",
        "    for pos in positive_negations:\n",
        "        vec_p =  d2vModel.infer_vector([pos])\n",
        "        #print(vec_p)\n",
        "        cos_p = cos_p - spatial.distance.cosine(vec_main, vec_p)\n",
        "        #print(cos_p)\n",
        "\n",
        "\n",
        "\n",
        "    for neg in negative_negations:\n",
        "        vec_n =  d2vModel.infer_vector([neg])\n",
        "        #print(vec_n)\n",
        "        cos_n = cos_n - spatial.distance.cosine(vec_main, vec_n)\n",
        "        #print(cos_n)\n",
        "\n",
        "    #print(cos_p)\n",
        "    #print(cos_n)\n",
        "    if cos_p < cos_n:\n",
        "            dfPangLee2.loc[index, 'score_c'] = 0\n",
        "            if row[\"ActualLabel\"] == 0:\n",
        "                 dfPangLee2.loc[index, 'comp_c'] = \"match\"\n",
        "            else:\n",
        "                 dfPangLee2.loc[index, 'comp_c'] = \"not match\"\n",
        "    else:\n",
        "            dfPangLee2.loc[index, 'score_c'] = 1\n",
        "            if row[\"ActualLabel\"] == 1:\n",
        "               dfPangLee2.loc[index, 'comp_c'] = \"match\"\n",
        "            else:\n",
        "               dfPangLee2.loc[index, 'comp_c'] = \"not match\"\n",
        "\n",
        "    dfPangLee2.loc[index, 'cos_p'] = cos_p\n",
        "    dfPangLee2.loc[index, 'cos_n'] = cos_n\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_L9Prj3tCkg"
      },
      "source": [
        "# Distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7A5o4JlWejs"
      },
      "outputs": [],
      "source": [
        "def Calculate_Word_Distance(sent1,sent2):\n",
        "    sent1 = preprocess(sent1)\n",
        "    sent2 = preprocess(sent2)\n",
        "    distance = abs (w2vMovie.wv.wmdistance(sent1, sent2))\n",
        "    #print('distance = %.4f' % distance)\n",
        "    return distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbSpTXjPDqdL"
      },
      "outputs": [],
      "source": [
        "#dfPangLee2 = dfPangLee2[dfPangLee2[\"id\"] < 3 ]\n",
        "for index, row in dfPangLee2.iterrows():\n",
        "    #text = preprocess(row['ActualText'])\n",
        "    text = row[\"PreProcessed\"]\n",
        "\n",
        "\n",
        "    positives = row[\"Positives\"].replace('[','').replace(']','').replace(\"'\",'').replace(' ','').split(',')\n",
        "    negatives = row[\"Negatives\"].replace('[','').replace(']','').replace(\"'\",'').replace(' ','').split(',')\n",
        "\n",
        "    positive_negations = row[\"Positive_Negations\"].replace('[','').replace(']','').replace(\"'\",'').replace(' ','').split(',')\n",
        "    negative_negations = row[\"Negative_Negations\"].replace('[','').replace(']','').replace(\"'\",'').replace(' ','').split(',')\n",
        "\n",
        "    #Mean distance\n",
        "    distance_p = 0\n",
        "    distance_n = 0\n",
        "\n",
        "    positives2 = list(dict.fromkeys(positives))\n",
        "    negatives2 = list(dict.fromkeys(negatives))\n",
        "\n",
        "    positive_negations2 = list(dict.fromkeys(positive_negations))\n",
        "    negative_negations2 = list(dict.fromkeys(negative_negations))\n",
        "\n",
        "\n",
        "    #positives2 = positives\n",
        "    #negatives2 = negatives\n",
        "    positives2 = ' '.join(dict.fromkeys(positives2))\n",
        "    negatives2 = ' '.join(dict.fromkeys(negatives2))\n",
        "\n",
        "    positive_negations2 = ' '.join(dict.fromkeys(positive_negations2))\n",
        "    negative_negations2 = ' '.join(dict.fromkeys(negative_negations2))\n",
        "\n",
        "\n",
        "    #print(positives2)\n",
        "    #print(negatives2)\n",
        "\n",
        "    distance_p =  Calculate_Word_Distance(row['ActualText'],positives2)\n",
        "    if len(positive_negations2) > 0:\n",
        "       distance_p = distance_p -  Calculate_Word_Distance(row['ActualText'], positive_negations2)\n",
        "    #print(distance_p)\n",
        "    distance_n =  Calculate_Word_Distance(row['ActualText'],negatives2)\n",
        "    if len(negative_negations2) > 0:\n",
        "        distance_n =  distance_n - Calculate_Word_Distance(row['ActualText'], negative_negations2)\n",
        "\n",
        "    #print(distance_n)\n",
        "\n",
        "    dfPangLee2.loc[index, 'dist_p'] = distance_p\n",
        "    dfPangLee2.loc[index, 'dist_n'] = distance_n\n",
        "\n",
        "    if distance_p < distance_n:\n",
        "      dfPangLee2.loc[index, 'score_dist'] = 1\n",
        "      if row[\"ActualLabel\"] == 1:\n",
        "           dfPangLee2.loc[index, 'comp_dist'] = \"match\"\n",
        "      else:\n",
        "            dfPangLee2.loc[index, 'comp_dist'] = \"not match\"\n",
        "    elif  distance_p > distance_n:\n",
        "      dfPangLee2.loc[index, 'score_dist'] = 0\n",
        "      if row[\"ActualLabel\"] == 0:\n",
        "           dfPangLee2.loc[index, 'comp_dist'] = \"match\"\n",
        "      else:\n",
        "            dfPangLee2.loc[index, 'comp_dist'] = \"not match\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slZEYiNVUhDw"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"comp_dist\"] == \"not match\" ]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwC37fvXdF_o"
      },
      "source": [
        "#  MINUS and DIVIDE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4h4U__gcX_V"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"comp_c\"] == \"not match\" ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfcUAGOXctxW"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"comp_dist\"] == \"not match\" ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06Qi96QWOqCY"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"comp_sc\"] == \"not match\" ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PedfHowzct3p"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"comp_sc\"] == \"not match\" ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dXDdzzaJO6g"
      },
      "outputs": [],
      "source": [
        "def add_result_positive_minus (row):\n",
        "  return (row['cos_p'] + row['softcos_p']) - row['dist_p']\n",
        "\n",
        "\n",
        "def add_result_negative_minus (row):\n",
        "  return (row['cos_n'] + row['softcos_n']) - row['dist_n']\n",
        "\n",
        "\n",
        "def add_result_total_minus (row):\n",
        "  if row['result_positive_minus'] > row['result_negative_minus']:\n",
        "     return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def add_result_evaluation_minus (row):\n",
        "  if row['score_overall_minus'] == row['ActualLabel']:\n",
        "    return \"match\"\n",
        "  else:\n",
        "    return \"not match\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRv2i-tYJNzn"
      },
      "outputs": [],
      "source": [
        "dfPangLee2['result_positive_minus'] = dfPangLee2.apply (lambda row: add_result_positive_minus(row), axis=1)\n",
        "dfPangLee2['result_negative_minus'] = dfPangLee2.apply (lambda row: add_result_negative_minus(row), axis=1)\n",
        "dfPangLee2['score_overall_minus'] = dfPangLee2.apply (lambda row: add_result_total_minus(row), axis=1)\n",
        "dfPangLee2['evaluation_minus'] = dfPangLee2.apply (lambda row: add_result_evaluation_minus(row), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Meh5eQHoLdrx"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"evaluation_minus\"] == \"not match\" ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Smr0axXbRxqy"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"evaluation_minus\"] == \"match\" ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSrwqwlZi0S0"
      },
      "outputs": [],
      "source": [
        "def add_result_positive_scs (row):\n",
        "  return (row['cos_p'] + row['softcos_p'])\n",
        "\n",
        "\n",
        "def add_result_negative_scs (row):\n",
        "  return (row['cos_n'] + row['softcos_n'])\n",
        "\n",
        "\n",
        "def add_result_total_scs (row):\n",
        "  if row['csc_p'] > row['csc_n']:\n",
        "     return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def add_result_evaluation_scs (row):\n",
        "  if row['score_csc'] == row['ActualLabel']:\n",
        "    return \"match\"\n",
        "  else:\n",
        "    return \"not match\"\n",
        "\n",
        "dfPangLee2['csc_p'] = dfPangLee2.apply (lambda row: add_result_positive_scs(row), axis=1)\n",
        "dfPangLee2['csc_n'] = dfPangLee2.apply (lambda row: add_result_negative_scs(row), axis=1)\n",
        "dfPangLee2['score_csc'] = dfPangLee2.apply (lambda row: add_result_total_scs(row), axis=1)\n",
        "dfPangLee2['comp_csc'] = dfPangLee2.apply (lambda row: add_result_evaluation_scs(row), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYK-fLlhjWSA"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"comp_csc\"] == \"not match\" ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_wzhxeDRtFk"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"comp_csc\"] == \"match\" ]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG1OQN0Mnzt0"
      },
      "source": [
        "# MIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRmj2z3Fn1tM"
      },
      "outputs": [],
      "source": [
        "def add_result_mix (row):\n",
        "  #score = ((row['cos_p'] + row['softcos_p']) - (row['cos_n'] + row['softcos_n']))/(row['dist_p'] + row['dist_n'])\n",
        "  #score = ((row['cos_p'] + row['softcos_p']) - row['dist_p']) - ((row['cos_n'] + row['softcos_n'])-row['dist_n'] )\n",
        "  #score = ((row['cos_p'] + row['softcos_p'])/row['dist_p'])  - ((row['cos_n'] + row['softcos_n'])/row['dist_n'])\n",
        "  #score2 = row['dist_p'] - row['dist_n']\n",
        "  if ((row['cos_p'] + row['softcos_p'])> (row['cos_n'] + row['softcos_n'])) and (row['dist_p'] < row['dist_n'] ):\n",
        "    score = 1\n",
        "  elif ((row['cos_p'] + row['softcos_p'])< (row['cos_n'] + row['softcos_n'])) and (row['dist_p'] > row['dist_n'] ):\n",
        "    score = 0\n",
        "  else:\n",
        "    if row['dist_p'] == 0 or row['dist_p'] == \"inf\":\n",
        "      score = 1\n",
        "    elif row['dist_n'] == 0 or row['dist_n'] == \"inf\":\n",
        "      score = 0\n",
        "    else:\n",
        "          temp = ((row['cos_p'] + row['softcos_p'])/row['dist_p'])  - ((row['cos_n'] + row['softcos_n'])/row['dist_n'])\n",
        "          if temp >0:\n",
        "            score = 1\n",
        "          else:\n",
        "            score = 0\n",
        "  return score\n",
        "\n",
        "def mix_eval (row):\n",
        "  if row['MIX'] == row['ActualLabel']:\n",
        "    return \"match\"\n",
        "  else:\n",
        "    return \"not match\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row"
      ],
      "metadata": {
        "id": "8Y8SjNI2tJf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAjGR9UKpRWx"
      },
      "outputs": [],
      "source": [
        "dfPangLee2['MIX'] = dfPangLee2.apply (lambda row: add_result_mix (row), axis=1)\n",
        "predictions = dfPangLee2.apply (lambda row: add_result_mix (row), axis=1)\n",
        "dfPangLee2['evaluation_MIX'] = dfPangLee2.apply (lambda row: mix_eval(row), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLUqljpIpma0"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"MIX\"] ==0 ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3qVC8FKbYo-"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"MIX\"] ==1 ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3byXlBsSphzx"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"evaluation_MIX\"] == \"not match\" ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gHJumnErHb-"
      },
      "outputs": [],
      "source": [
        "accuracy_score(predictions,targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfUqwL_7OeqB"
      },
      "source": [
        "# Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-kCpNp6OhRs"
      },
      "outputs": [],
      "source": [
        "#dfPangLee2.to_csv('/MYDRIVE/My Drive/Colab Notebooks/SSTSA/data/resultAll-dvd-01-02-20.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKKN1ByJkOI1"
      },
      "source": [
        "# VADER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exBBy56glKdY"
      },
      "outputs": [],
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "def eval_vader (row):\n",
        "  if row['VADER'] == row['ActualLabel']:\n",
        "    return \"match\"\n",
        "  else:\n",
        "    return \"not match\"\n",
        "\n",
        "def text_sentiment_vader(row):\n",
        " vs = analyzer.polarity_scores(row[\"ActualText\"])\n",
        " return int(vs.get(\"compound\")>0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "652f9FDMmv4D"
      },
      "outputs": [],
      "source": [
        " predictions = dfPangLee2.apply (lambda row: text_sentiment_vader(row), axis=1)\n",
        " dfPangLee2['VADER'] = dfPangLee2.apply (lambda row: text_sentiment_vader(row), axis=1)\n",
        " dfPangLee2['comp_VADER'] = dfPangLee2.apply (lambda row: eval_vader(row), axis=1)\n",
        " print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrgZmUtBliGq"
      },
      "outputs": [],
      "source": [
        "accuracy_score( predictions.values  , targets )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfrSqqkSzX4l"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"comp_VADER\"] == \"not match\" ]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcOYXoaSlM1e"
      },
      "source": [
        "# TEXTBLOB"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfPangLee2.columns"
      ],
      "metadata": {
        "id": "rf_yioOLQjvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utryhHnjlPfc"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def eval_blob (row):\n",
        "  if row['BLOB'] == row['ActualLabel']:\n",
        "    return \"match\"\n",
        "  else:\n",
        "    return \"not match\"\n",
        "\n",
        "def text_sentiment_blob(row):\n",
        "    testimonial = TextBlob(row[\"ActualText\"])\n",
        "    score = testimonial.sentiment.polarity\n",
        "    if score > 0:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = dfPangLee2.apply (lambda row: text_sentiment_blob(row), axis=1)\n",
        "dfPangLee2['BLOB'] = predictions\n",
        "#dfPangLee2['BLOB'] = dfPangLee2.apply (lambda row: text_sentiment_blob(row), axis=1)\n",
        "dfPangLee2['comp_BLOB'] = dfPangLee2.apply (lambda row: eval_blob(row), axis=1)\n",
        "#accuracy_score(predictions,targets)"
      ],
      "metadata": {
        "id": "tLwPgtzDP6J-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_sW80dxDKk1"
      },
      "outputs": [],
      "source": [
        "accuracy_score(predictions,targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ri-9g9LiDMDT"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"comp_BLOB\"] == \"not match\" ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Mb0GWRrlWuf"
      },
      "outputs": [],
      "source": [
        "analyzer.polarity_scores(\"The food as great!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNm_Y4cilypf"
      },
      "source": [
        "# FLAIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HnlpOCtl2iE"
      },
      "outputs": [],
      "source": [
        "from flair.models import TextClassifier\n",
        "from flair.data import Sentence\n",
        "classifierFlair = TextClassifier.load('en-sentiment')\n",
        "\n",
        "def eval_flair (row):\n",
        "  if row['FLAIR'] == row['ActualLabel']:\n",
        "    return \"match\"\n",
        "  else:\n",
        "    return \"not match\"\n",
        "\n",
        "def text_sentiment_flair(row):\n",
        "  sentence = Sentence(row[\"ActualText\"])\n",
        "  classifierFlair.predict(sentence)\n",
        "  if sentence.labels[0].value == \"POSITIVE\":\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = dfPangLee2.apply (lambda row: text_sentiment_flair(row), axis=1)\n",
        "dfPangLee2['FLAIR'] = predictions\n",
        "#dfPangLee2['FLAIR'] = dfPangLee2.apply (lambda row: text_sentiment_flair(row), axis=1)\n",
        "dfPangLee2['comp_FLAIR'] = dfPangLee2.apply (lambda row: eval_flair(row), axis=1)"
      ],
      "metadata": {
        "id": "ozkX-vGXRJ8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBcvU9-Nl7LQ"
      },
      "outputs": [],
      "source": [
        "accuracy_score(predictions.values,targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0KH9GTttkJt"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"comp_FLAIR\"] == \"not match\" ]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2YAGw_ieXT5"
      },
      "source": [
        "# AFINN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d60YTJfEfCSD"
      },
      "outputs": [],
      "source": [
        "from afinn import Afinn\n",
        "afn = Afinn()\n",
        "def eval_afinn (row):\n",
        "  if row['FLAIR'] == row['ActualLabel']:\n",
        "    return \"match\"\n",
        "  else:\n",
        "    return \"not match\"\n",
        "\n",
        "def text_sentiment_afinn(row):\n",
        "  score = afn.score(row[\"ActualText\"])\n",
        "  if score > 0:\n",
        "    return 1\n",
        "  elif score < 0:\n",
        "    return 0\n",
        "  else:\n",
        "      return score\n",
        "\n",
        "\n",
        "\n",
        "predictions = dfPangLee2.apply (lambda row: text_sentiment_afinn(row), axis=1)\n",
        "dfPangLee2['AFINN'] = dfPangLee2.apply (lambda row: text_sentiment_afinn(row), axis=1)\n",
        "dfPangLee2['comp_AFINN'] = dfPangLee2.apply (lambda row: eval_afinn(row), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5VqzqGAfFZz"
      },
      "outputs": [],
      "source": [
        "accuracy_score( predictions , targets )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBsMYhUkfIJ8"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"comp_AFINN\"] == \"not match\" ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPM91VqVk3Ee"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"comp_AFINN\"] == \"match\" ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VV4WUZp1k9pm"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"comp_AFINN\"] == \"match\" ]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cwx04RZvu9Zo"
      },
      "source": [
        "# SentiStrength"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_SZZmfbvAg4"
      },
      "source": [
        "https://github.com/zhunhung/Python-SentiStrength"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woi1J5KkOU4O"
      },
      "outputs": [],
      "source": [
        "pip install sentistrength"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa_epsbIvDVY"
      },
      "outputs": [],
      "source": [
        "from sentistrength import PySentiStr\n",
        "\n",
        "\n",
        "def eval_senti (row):\n",
        "  if row['SENTI'] == row['ActualLabel']:\n",
        "    return \"match\"\n",
        "  else:\n",
        "    return \"not match\"\n",
        "\n",
        "def text_sentiment_senti(row):\n",
        "  score = senti.getSentiment(row[\"ActualText\"], score=\"binary\")\n",
        "  #print(score[0])\n",
        "  if score[0] >= 0:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "senti = PySentiStr()\n",
        "senti.setSentiStrengthPath('/MYDRIVE/My Drive/Colab Notebooks/SSTSA/data/SentiStrengthCom.jar') # Note: Provide absolute path instead of relative path\n",
        "senti.setSentiStrengthLanguageFolderPath('/MYDRIVE/My Drive/Colab Notebooks/SSTSA/data/SentiStrengthData/') # Note: Provide absolute path instead of relative path\n",
        "score = senti.getSentiment(\"I hate you\")\n",
        "print(score[0])\n"
      ],
      "metadata": {
        "id": "ThEzthMV4cVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIKTqgBWN0YE"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "predictions = dfPangLee2.apply (lambda row: text_sentiment_senti(row), axis=1)\n",
        "dfPangLee2['SENTI'] = predictions\n",
        "#dfPangLee2['SENTI'] = dfPangLee2.apply (lambda row: text_sentiment_senti(row), axis=1)\n",
        "dfPangLee2['comp_SENTI'] = dfPangLee2.apply (lambda row: eval_senti(row), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score( predictions , targets )"
      ],
      "metadata": {
        "id": "WxuWqiJjMP7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ1YDI-f8qM9"
      },
      "source": [
        "# SAVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvZjv5zY8q8b"
      },
      "outputs": [],
      "source": [
        "dfPangLee2.to_csv('/MYDRIVE/My Drive/Colab Notebooks/SSTSA/data/resultAll-MR-01-02-22.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOHnY8_gO7F1"
      },
      "outputs": [],
      "source": [
        "dfPangLee2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuRccd2kPWxc"
      },
      "source": [
        "# Accuracy Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUKJAkM7PeFv"
      },
      "source": [
        "## Minus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOAOXzjXPjOb"
      },
      "outputs": [],
      "source": [
        "dfPangLee2.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JD7vHUJwPrBm"
      },
      "outputs": [],
      "source": [
        "predictions = dfPangLee2[\"score_overall_minus\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgZRgoOpPWGj"
      },
      "outputs": [],
      "source": [
        "accuracy_score(predictions,targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnGB2VX9QgbZ"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"evaluation_minus\"] == \"not match\" ]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLnOUmGFQEE9"
      },
      "source": [
        "## csc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pUQFEljQGe-"
      },
      "outputs": [],
      "source": [
        "predictions = dfPangLee2[\"score_csc\"]\n",
        "\n",
        "print(accuracy_score(predictions,targets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuVoJ0pcQKyA"
      },
      "outputs": [],
      "source": [
        "accuracy_score(predictions,targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZKY3qZoQlkJ"
      },
      "outputs": [],
      "source": [
        "print(len(dfPangLee2[dfPangLee2[\"comp_csc\"] == \"not match\" ]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwi2qCi9OINk"
      },
      "source": [
        "## ِDist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pX7U1NNKOLlt"
      },
      "outputs": [],
      "source": [
        "predictions = dfPangLee2[\"score_dist\"]\n",
        "\n",
        "print(accuracy_score(predictions,targets))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arxQrJgITm5X"
      },
      "source": [
        "## cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jd-U12tuTo19"
      },
      "outputs": [],
      "source": [
        "predictions = dfPangLee2[\"score_c\"]\n",
        "\n",
        "print(accuracy_score(predictions,targets))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp60rTV3T7pZ"
      },
      "source": [
        "## soft cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnpV46xhT90y"
      },
      "outputs": [],
      "source": [
        "predictions = dfPangLee2[\"score_sc\"]\n",
        "\n",
        "print(accuracy_score(predictions,targets))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "L2dU67GHyuyq",
        "B_L9Prj3tCkg",
        "kKKN1ByJkOI1",
        "tcOYXoaSlM1e",
        "wNm_Y4cilypf",
        "F2YAGw_ieXT5",
        "hwi2qCi9OINk",
        "arxQrJgITm5X",
        "Mp60rTV3T7pZ"
      ],
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNt8XCH+3Gx5D84I5pzaw5p",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}